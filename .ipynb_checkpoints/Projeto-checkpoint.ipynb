{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZwGWSSJkkqd"
   },
   "source": [
    "\n",
    "# Cloud liveness detection\n",
    "\n",
    "O setor de fraudes da Quantumn Finance identificou um problema recorrente de clientes que contestam a contratação de serviços específicos, como crédito pessoal, mesmo após a realização dos protocolos de segurança da senha. Apesar da autenticação por senha, o banco arca com reembolsos e medidas de contenção para evitar processos judiciais, pois os clientes alegam terem sido vítimas de invasão por hackers ou outras atividades fraudulentas.\n",
    "\n",
    "**Amazon Rekognition**\n",
    "\n",
    "O Amazon Rekognition é um serviço de visão computacional e aprendizado de máquina baseado em nuvem que oferece diversas funcionalidades para análise de imagens e vídeos, incluindo:\n",
    "\n",
    "* Detecção de rostos: Localiza e identifica rostos em imagens e vídeos.\n",
    "Reconhecimento facial: Compara rostos em imagens e vídeos com rostos em um banco de dados para verificar a identidade de uma pessoa.\n",
    "* Detecção de emoções: Analisa as emoções presentes em rostos em imagens e vídeos.\n",
    "*Detecção de atividades: Reconhece atividades como comer, beber e falar em imagens e vídeos.\n",
    "Análise de cenas: Identifica e classifica objetos, cenas e atividades em imagens e vídeos.\n",
    "\n",
    "\n",
    "\n",
    "Participantes do projeto:\n",
    "\n",
    "\n",
    "| Nome dos Integrantes     | RM            | Turma |\n",
    "| :----------------------- | :------------- | :-----: |\n",
    "| Igor Mazzeto             | RM 352368      | 5DTSR |\n",
    "| Gildo Moraes             | RM 352486      | 5DTSR |\n",
    "| Luiz Henrique             | RM 352631      | 5DTSR |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgXjyyPYyTwx"
   },
   "source": [
    "## Premissas e contexto do projeto\n",
    "\n",
    "Para esse projeto vamos utilizar as seguintes premissas:\n",
    "\n",
    "*   **O usuário da aplicação enviará várias imagens (fotos) para realizar a autênticação junto a plataforma da instituição**\n",
    "*   As imagens passarão por um processo de autenticação comparando a similaridade das imagens/fotos enviadas com a imagem fonte (source) do documento enviado no momento\n",
    "* No final, caso a vivacidade (liveness) não for comprovada, o usuário terá acesso negado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CK79k3G4retb"
   },
   "source": [
    "# Recursos utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkFn_LoVkjop",
    "outputId": "72d9cb96-4947-49cd-9b3a-521e555bb90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.37.13-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.13 (from boto3)\n",
      "  Downloading botocore-1.37.13-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3)\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.38.0,>=1.37.13->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.38.0,>=1.37.13->boto3) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.13->boto3) (1.16.0)\n",
      "Downloading boto3-1.37.13-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.37.13-py3-none-any.whl (13.4 MB)\n",
      "   ---------------------------------------- 0.0/13.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/13.4 MB 7.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.6/13.4 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.5/13.4 MB 7.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.0/13.4 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.6/13.4 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.2/13.4 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.5/13.4 MB 7.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.1/13.4 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.4/13.4 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.37.13 botocore-1.37.13 s3transfer-0.11.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.37.13 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Instalação da biblioteca boto3\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dmvn8dmskomA"
   },
   "outputs": [],
   "source": [
    "# Bibliotecas utilizadas\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SxlREcK1jds-"
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams as mpl_param\n",
    "\n",
    "mpl_param[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IQ7tZ8ajlyMx"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9U52NPPkujH"
   },
   "source": [
    "## Credenciais AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkNSk1TTz_YB"
   },
   "source": [
    "Credenciais criadas juntos a Amazon AWS, serão desativadas em breve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "k9ZCe5gxkqWL"
   },
   "outputs": [],
   "source": [
    "ACCESS_ID = \"AKIA35HPYNCFJNZXS7N7\"\n",
    "ACCESS_KEY = \"qA/iOrb1GSjvfVPSkpcIh6A5UTx9bRAdBEKsYAm3\"\n",
    "REGION = \"us-east-1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nY3L-yi5lIND"
   },
   "source": [
    "## Repositório Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTuMpI380GOE"
   },
   "source": [
    "Repositório do github utilizado para executar o código e armazenar os arquivos utilizadp=os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0MseThJlIwv",
    "outputId": "4e2b137b-11bc-4f34-c49e-c5d8fe48959e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FIAP-cognitive-environments'...\n",
      "remote: Enumerating objects: 87, done.\u001b[K\n",
      "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
      "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
      "remote: Total 87 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (87/87), 30.58 MiB | 19.69 MiB/s, done.\n",
      "Resolving deltas: 100% (9/9), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/JVSCARANO/FIAP-6D-CongnitiveEnviroments.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv6AYOrkob9w"
   },
   "source": [
    "## Imagens utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iNvR028QOzTc"
   },
   "outputs": [],
   "source": [
    "# caminhos\n",
    "\n",
    "chines1 = \"imagens/chines-1.png\"\n",
    "cnh = \"imagens/cnh.png\"\n",
    "igor1 = \"imagens/igor-1-2.jpg\"\n",
    "igor2_oculos = \"imagens/igor-2.jpg\"\n",
    "igor4_sol = \"imagens/igor-4.jpeg\"\n",
    "igor5_lattes = \"imagens/igor-5.jpeg\"\n",
    "joao = \"imagens/joao-1.jpg\"\n",
    "pedro = \"imagens/pedro-1.png\"\n",
    "igor6 = \"imagens/igor-6.png\"\n",
    "igor7 = \"imagens/igor-7.png\"\n",
    "tulio1 = \"imagens/tulio-1.png\"\n",
    "artur1 = \"imagens/artur-1.png\"\n",
    "breno1 = \"imagens/breno-1.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aPUReMVRdQe6"
   },
   "outputs": [],
   "source": [
    "image_paths = [chines1,igor1,igor2_oculos,igor4_sol,igor5_lattes,joao,pedro,igor6,igor7,tulio1,artur1,breno1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOs7O7wbVmiP"
   },
   "source": [
    "## Checagem e validação das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YoxZ7DP0S-f"
   },
   "source": [
    "**Função `is_valid_image`**:\n",
    "\n",
    "Verifica se uma imagem é válida com base em seu tamanho.\n",
    "\n",
    "- **Abre a imagem**: Usa a biblioteca `PIL` para abrir a imagem no caminho fornecido (`image_path`).\n",
    "\n",
    "- **Verifica o Tamanho da Imagem**: Obtém as dimensões da imagem e calcula o total de pixels (largura x altura).\n",
    "- **Verifica o Limite de Megapixels**: Se o total de pixels exceder 15 milhões (equivalente a 15 megapixels), a função retorna `False`.\n",
    "\n",
    "- **Retorno**: Se a imagem não exceder o limite de megapixels e foi aberta com sucesso, a função retorna `True`. Se ocorrer um erro ao abrir a imagem, como um arquivo inexistente ou corrompido, retorna `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "79WG4GRGVl9X"
   },
   "outputs": [],
   "source": [
    "def is_valid_image(image_path):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Verificar tamanho da imagem\n",
    "            width, height = img.size\n",
    "            # Calcular o número máximo de pixels (15 megapixels = 15.000.000 pixels)\n",
    "            if width * height > 15_000_000:\n",
    "                return False\n",
    "            return True\n",
    "    except IOError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VES0CPmF0n7s"
   },
   "source": [
    "**Função `target_images`:**\n",
    "\n",
    " Processa uma lista de caminhos de imagens (`image_paths`) e retorna uma lista apenas com os caminhos das imagens válidas.\n",
    "\n",
    " - **Cria uma Lista para Imagens Válidas**: Inicializa uma lista vazia chamada `valid_image_paths` para armazenar os caminhos das imagens que atendem aos critérios de validação.\n",
    "\n",
    " - **Itera Sobre os Caminhos das Imagens**: Percorre cada caminho na lista `image_paths`.\n",
    "\n",
    " - **Valida cada inagem**: Usa a função `is_valid_image` para verificar se a imagem no caminho atual é válida.\n",
    "\n",
    " - **Armazena Imagens Válidas**: Se a imagem for válida, adiciona o caminho à lista `valid_image_paths`. Caso contrário, imprime uma mensagem indicando que a imagem é inválida ou está fora do tamanho permitido.\n",
    "\n",
    " - **Retorna a Lista de Imagens Válidas**: Após a verificação de todas as imagens, a função retorna a lista `valid_image_paths` contendo apenas os caminhos das imagens que passaram na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KnwmPq57Xfvb"
   },
   "outputs": [],
   "source": [
    "def target_images(image_paths):\n",
    "    valid_image_paths = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        if is_valid_image(image_path):\n",
    "            valid_image_paths.append(image_path)\n",
    "        else:\n",
    "            print(f\"Imagem inválida ou fora do tamanho permitido: {image_path}\")\n",
    "\n",
    "    return valid_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uD-uvmOXYwgC",
    "outputId": "3e508874-4d0d-4032-93d5-6f7c75bcdd56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagens/chines-1.png', 'imagens/igor-1-2.jpg', 'imagens/igor-2.jpg', 'imagens/igor-4.jpeg', 'imagens/igor-5.jpeg', 'imagens/joao-1.jpg', 'imagens/pedro-1.png', 'imagens/igor-6.png', 'imagens/igor-7.png', 'imagens/tulio-1.png', 'imagens/artur-1.png', 'imagens/breno-1.png']\n"
     ]
    }
   ],
   "source": [
    "target_image_paths = target_images(image_paths)\n",
    "print(target_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V58MuyDDogx"
   },
   "source": [
    "# Etapas para comparação das imagens\n",
    "\n",
    "\n",
    "- Recepção da imagem\n",
    "- Verificação da imagem\n",
    "  - Verificar olhos fechados\n",
    "  - Verificar oclusão\n",
    "  - Verificar óculos de sol\n",
    "- Realizar comparação\n",
    "- Verificar vivacidade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drN33fq51gRf"
   },
   "source": [
    "**Função `get_face_details`:**\n",
    "\n",
    "- Abre o arquivo da imagem: Abre o arquivo especificado por `file_name` em modo binário (`\"rb\"`), lê seu conteúdo e converte para um objeto `bytearray`.\n",
    "\n",
    "- Requisição de detecção de rostos: Envia uma requisição ao serviço Rekognition para detectar rostos na imagem fornecida. Especifica que deseja atributos como \"EYES_OPEN\", \"FACE_OCCLUDED e \"SUNGLASSES\" na resposta.\n",
    "\n",
    "- Retorna `response`: Retorna a resposta do serviço Rekognition, que contém detalhes sobre os rostos detectados na imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iWBuZ6jZDdjQ"
   },
   "outputs": [],
   "source": [
    "def get_face_details(file_name):\n",
    "  # conversão para binário\n",
    "  with open(file_name, \"rb\") as file:\n",
    "    img_file = file.read()\n",
    "    bytes_file = bytearray(img_file)\n",
    "\n",
    "  # abrindo a sessão\n",
    "  session = boto3.Session(aws_access_key_id=ACCESS_ID, aws_secret_access_key= ACCESS_KEY)\n",
    "\n",
    "  # criando o cliente\n",
    "  client = session.client(\"rekognition\", region_name=REGION)\n",
    "\n",
    "  # criando a requisição\n",
    "  response = client.detect_faces(\n",
    "      Image={'Bytes': bytes_file},\n",
    "      Attributes=[\"EYES_OPEN\", \"FACE_OCCLUDED\", \"SUNGLASSES\"]\n",
    "  )\n",
    "\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zM4KBXsD1_DV"
   },
   "source": [
    "\n",
    "**Função `get_face_attributes2`**:\n",
    "\n",
    "- Detalhes da face: Chama a função `get_face_details` para obter os detalhes dos rostos da imagem especificada.\n",
    "\n",
    "- Detecção de rosto: Obtém a lista de detalhes da face da resposta e verifica se há algum rosto detectado. Se não houver, retorna uma mensagem de erro.\n",
    "\n",
    "- Detecção dos atributos: Pega os atributos da primeira face detectada. Os atributos incluem a abertura dos olhos, a presença de óculos escuros e se o rosto está oculto.\n",
    "\n",
    "- Checagem do nível de confiaça: Compara o nível de confiança de cada atributo com o nível mínimo especificado (`confidence_level`). Se algum atributo tiver um nível de confiança abaixo do especificado:\n",
    "  - Cria uma lista de razões para o resultado não ser aprovado.\n",
    "  - Retorna uma mensagem de erro com detalhes dos atributos e razões.\n",
    "\n",
    "- Checagem dos atributos mencionados: Se os níveis de confiança forem suficientes:\n",
    "  - Verifica o valor de cada atributo (`eyes_open_value`, `sunglasses_value`, `face_occluded_value`).\n",
    "  - Retorna uma mensagem específica se a imagem não for aprovada por causa dos olhos fechados, óculos escuros ou rosto parcialmente oculto.\n",
    "\n",
    "- Aprovação: Se todos os atributos estiverem de acordo, retorna uma mensagem indicando que a imagem foi aprovada, juntamente com os valores e níveis de confiança dos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2EO5dtbXczwt"
   },
   "outputs": [],
   "source": [
    "def get_face_attributes2(file_name, confidence_level):\n",
    "    # Função fictícia para obter os detalhes da face\n",
    "    response = get_face_details(file_name)\n",
    "    face_details = response.get(\"FaceDetails\", [])\n",
    "\n",
    "    if not face_details:\n",
    "        return \"Imagem não pode ser processada, por favor tente novamente\"\n",
    "\n",
    "    face_attributes = face_details[0]  # First detected face\n",
    "\n",
    "    eyes_open = face_attributes.get(\"EyesOpen\", {})\n",
    "    sunglasses = face_attributes.get(\"Sunglasses\", {})\n",
    "    face_occluded = face_attributes.get(\"FaceOccluded\", {})\n",
    "\n",
    "    # Check confidence levels\n",
    "    if (eyes_open.get(\"Confidence\", 0) < confidence_level or\n",
    "        sunglasses.get(\"Confidence\", 0) < confidence_level or\n",
    "        face_occluded.get(\"Confidence\", 0) < confidence_level):\n",
    "        reasons = []\n",
    "        if eyes_open.get(\"Confidence\", 0) < confidence_level:\n",
    "            reasons.append(\"Abertura dos olhos não é confiável o suficiente.\")\n",
    "        if sunglasses.get(\"Confidence\", 0) < confidence_level:\n",
    "            reasons.append(\"Óculos escuros não são confiáveis o suficiente.\")\n",
    "        if face_occluded.get(\"Confidence\", 0) < confidence_level:\n",
    "            reasons.append(\"O rosto está parcialmente oculto.\")\n",
    "\n",
    "        return {\n",
    "            \"Message\": \"Imagem não pode ser processada, por favor tente novamente.\",\n",
    "            \"Details\": reasons,\n",
    "            \"EyesOpen\": {\n",
    "                \"Value\": eyes_open.get(\"Value\", None),\n",
    "                \"Confidence\": eyes_open.get(\"Confidence\")\n",
    "            },\n",
    "            \"Sunglasses\": {\n",
    "                \"Value\": sunglasses.get(\"Value\", None),\n",
    "                \"Confidence\": sunglasses.get(\"Confidence\")\n",
    "            },\n",
    "            \"FaceOccluded\": {\n",
    "                \"Value\": face_occluded.get(\"Value\", None),\n",
    "                \"Confidence\": face_occluded.get(\"Confidence\")\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Verifica nível de confiança\n",
    "    eyes_open_value = eyes_open.get(\"Value\", None)\n",
    "    sunglasses_value = sunglasses.get(\"Value\", None)\n",
    "    face_occluded_value = face_occluded.get(\"Value\", None)\n",
    "\n",
    "    # Aprovação da imagem\n",
    "    if not eyes_open_value:\n",
    "        return {\n",
    "            \"Message\": \"Imagem não pode ser processada porque os olhos estão fechados.\",\n",
    "            \"EyesOpen\": {\n",
    "                \"Value\": eyes_open_value,\n",
    "                \"Confidence\": eyes_open.get(\"Confidence\")\n",
    "            },\n",
    "            \"Sunglasses\": {\n",
    "                \"Value\": sunglasses_value,\n",
    "                \"Confidence\": sunglasses.get(\"Confidence\")\n",
    "            },\n",
    "            \"FaceOccluded\": {\n",
    "                \"Value\": face_occluded_value,\n",
    "                \"Confidence\": face_occluded.get(\"Confidence\")\n",
    "            }\n",
    "        }\n",
    "    if sunglasses_value:\n",
    "        return {\n",
    "            \"Message\": \"Imagem não pode ser processada porque óculos escuros foram detectados.\",\n",
    "            \"EyesOpen\": {\n",
    "                \"Value\": eyes_open_value,\n",
    "                \"Confidence\": eyes_open.get(\"Confidence\")\n",
    "            },\n",
    "            \"Sunglasses\": {\n",
    "                \"Value\": sunglasses_value,\n",
    "                \"Confidence\": sunglasses.get(\"Confidence\")\n",
    "            },\n",
    "            \"FaceOccluded\": {\n",
    "                \"Value\": face_occluded_value,\n",
    "                \"Confidence\": face_occluded.get(\"Confidence\")\n",
    "            }\n",
    "        }\n",
    "    if face_occluded_value:\n",
    "        return {\n",
    "            \"Message\": \"Imagem não pode ser processada porque o rosto está parcialmente oculto.\",\n",
    "            \"EyesOpen\": {\n",
    "                \"Value\": eyes_open_value,\n",
    "                \"Confidence\": eyes_open.get(\"Confidence\")\n",
    "            },\n",
    "            \"Sunglasses\": {\n",
    "                \"Value\": sunglasses_value,\n",
    "                \"Confidence\": sunglasses.get(\"Confidence\")\n",
    "            },\n",
    "            \"FaceOccluded\": {\n",
    "                \"Value\": face_occluded_value,\n",
    "                \"Confidence\": face_occluded.get(\"Confidence\")\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Verifica todos os checks\n",
    "    return {\n",
    "        \"Message\": \"Imagem aprovada\",\n",
    "        \"EyesOpen\": {\n",
    "            \"Value\": eyes_open_value,\n",
    "            \"Confidence\": eyes_open.get(\"Confidence\")\n",
    "        },\n",
    "        \"Sunglasses\": {\n",
    "            \"Value\": sunglasses_value,\n",
    "            \"Confidence\": sunglasses.get(\"Confidence\")\n",
    "        },\n",
    "        \"FaceOccluded\": {\n",
    "            \"Value\": face_occluded_value,\n",
    "            \"Confidence\": face_occluded.get(\"Confidence\")\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTdSpSMtrCRm"
   },
   "source": [
    "## Validação da imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zqjDEBe3Aff"
   },
   "source": [
    "**Função `validate_and_filter_images`:**\n",
    "\n",
    "- Inicializa Listas negrito: Cria duas listas vazias, `valid_images` para armazenar imagens aprovadas e `invalid_images` para armazenar imagens não aprovadas junto com os detalhes de erro.\n",
    "\n",
    "- Processa Cada Imagem: Percorre cada caminho de imagem na lista `target_image_paths` e usa a função `get_face_attributes2` para obter atributos da face e validar a imagem com base no nível de confiança fornecido (`confidence_level`).\n",
    "\n",
    "- Classifica Imagens:\n",
    "  - Se a resposta da função `get_face_attributes2` indica que a imagem foi aprovada (`\"Imagem aprovada\"`), adiciona o caminho da imagem à lista `valid_images`.\n",
    "  - Caso contrário, adiciona uma tupla contendo o caminho da imagem e o resultado da validação à lista `invalid_images`.\n",
    "\n",
    "- Imprime Detalhes de Imagens Inválidas:\n",
    "  - Para cada imagem na lista `invalid_images`, imprime uma mensagem indicando que a imagem foi removida e o motivo da rejeição.\n",
    "  - Se houver detalhes adicionais no resultado, imprime essas informações.\n",
    "\n",
    "- Retorna Imagens Válidas: Retorna a lista `valid_images` contendo apenas os caminhos das imagens que passaram na validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "igbw7bINc5aT"
   },
   "outputs": [],
   "source": [
    "def validate_and_filter_images(target_image_paths, confidence_level):\n",
    "    # Cria as listas vazias\n",
    "    valid_images = []\n",
    "    invalid_images = []\n",
    "\n",
    "    # iteração para cada imagem dentro do objeto\n",
    "    for image_path in target_image_paths:\n",
    "        result = get_face_attributes2(image_path, confidence_level)\n",
    "\n",
    "        # Se a imagem for aprovada, insere na lista\n",
    "        if result[\"Message\"] == \"Imagem aprovada\":\n",
    "            valid_images.append(image_path)\n",
    "        else:\n",
    "            invalid_images.append((image_path, result))\n",
    "\n",
    "    # Itera sob cada imagem reprovada e pegas os motivos\n",
    "    for image_path, result in invalid_images:\n",
    "        print(f\"Imagem removida: {image_path}\")\n",
    "        print(f\"Motivo: {result['Message']}\")\n",
    "        if 'Details' in result:\n",
    "            print(\"Detalhes adicionais:\")\n",
    "            for detail in result['Details']:\n",
    "                print(f\" - {detail}\")\n",
    "\n",
    "    return valid_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbLmjAm2NlE0"
   },
   "source": [
    "**Nível de confiança**\n",
    "\n",
    "O nível de confiança é extremamente importante para avaliação e classificação das imagens, podendo ser definidor na autenticação de um usuário. Por ser um parâmetro importante, optou-se por passá-lo nas funções para verificar o desempenho de cada imagem.\n",
    "\n",
    "Os manuais de melhores práticas no assunto recomendam a utilização de 99% no nível de confiança. Para esse projeto vamos utilizar o nível de 90% para aprimorar a qualidade das imagens aqui utilizadas.\n",
    "\n",
    "Como sugestão de melhoria para esse projeto, o ideal seria buscar imagens padronizadas no seu formato e tamanho de pixels para responder melhor as especificações da AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lU9-5PGEKufV"
   },
   "outputs": [],
   "source": [
    "confidence_level = 90.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x3c2eV1rFLX"
   },
   "source": [
    "Remoção das imagens inadequadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5yDxrMRdHjB",
    "outputId": "ca134115-ff88-4be2-a856-a1c71bb62a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagem removida: imagens/igor-4.jpeg\n",
      "Motivo: Imagem não pode ser processada, por favor tente novamente.\n",
      "Detalhes adicionais:\n",
      " - Óculos escuros não são confiáveis o suficiente.\n",
      "Imagem removida: imagens/igor-6.png\n",
      "Motivo: Imagem não pode ser processada porque o rosto está parcialmente oculto.\n",
      "Imagem removida: imagens/igor-7.png\n",
      "Motivo: Imagem não pode ser processada porque óculos escuros foram detectados.\n"
     ]
    }
   ],
   "source": [
    "# Filtra e valida imagens\n",
    "valid_images = validate_and_filter_images(target_image_paths, confidence_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtwzlyEirP36"
   },
   "source": [
    "Atribuição das variáveis que serão comparadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ULUZJ_kBp7VW"
   },
   "outputs": [],
   "source": [
    "target_image_paths = valid_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hf67p0qn-0eh"
   },
   "source": [
    "## Image Source\n",
    "\n",
    "Essa imagem será a referência que o modelo da AWS utilizará para realizar as comparações e finalmente autenticar a identidade de um eventual usuário da instituição bancária. Geralmente essas instituições solicitam documentos oficiais como a **Carteira Nacional de Habilitação** (CNH) ou o **Registro Geral** (RG) para armazenar em seus bancos de dados.\n",
    "\n",
    "Para esse projeto foi definida a utilização da CNH para realizar a autenticação. Portanto, o objeto *image_source* será utilizado como a referência para demais comparações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "cAsvBtMP-0CM",
    "outputId": "24513173-bd34-4f1d-9e18-385e21241e3f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpimg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_name_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagens/cnh.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m image_source \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(file_name_source)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image_source)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mpimg' is not defined"
     ]
    }
   ],
   "source": [
    "file_name_source = \"imagens/cnh.png\"\n",
    "image_source = mpimg.imread(file_name_source)\n",
    "plt.imshow(image_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9okgnldLVgyC"
   },
   "source": [
    "## Comparacão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGRqwOLd5Eze"
   },
   "source": [
    "**Função `compare_images`**:\n",
    "\n",
    "- Conversão em bytes: Lê a imagem de origem (`source_image_path`) e converte seu conteúdo para o formato binário (`bytearray`).\n",
    "\n",
    "- Cria um dicionário de resultados: Inicializa um dicionário vazio `results` para armazenar o resultado da comparação para cada imagem alvo.\n",
    "\n",
    "- Processa cada imagem alvo (targets):\n",
    "  - Para cada caminho de imagem alvo (`target_image_paths`):\n",
    "    - Converte a imagem alvo para o formato binário (`bytearray`).\n",
    "    - Usa o serviço Rekognition para comparar a imagem de origem com a imagem alvo, enviando ambas como bytes.\n",
    "\n",
    "- Analisa correspondências:\n",
    "  - Se a resposta da comparação contém correspondências de rosto (`'FaceMatches'`):\n",
    "    - Verifica cada correspondência para ver se a similaridade é maior ou igual ao nível de similaridade especificado (`similarity_level`).\n",
    "    - Se encontrar uma correspondência com similaridade suficiente, marca a imagem alvo como autenticada e armazena o resultado no dicionário `results`. Interrompe a verificação de outras correspondências para aquela imagem alvo.\n",
    "  - Se nenhuma correspondência for suficiente ou se não houver correspondência, marca a imagem alvo como não autenticada.\n",
    "\n",
    "- Results:retorna o dicionário `results`, que contém o status de autenticação (com ou sem correspondência suficiente) para cada imagem alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rln8rXdgWlvZ"
   },
   "outputs": [],
   "source": [
    "def compare_images(source_image_path, target_image_paths, similarity_level, aws_access_key_id, aws_secret_access_key, region_name):\n",
    "    # Abrindo a sessão com AWS\n",
    "    session = boto3.Session(aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "    client = session.client('rekognition', region_name=region_name)\n",
    "\n",
    "    # Convertendo a imagem de origem para o formato binário\n",
    "    with open(source_image_path, 'rb') as file:\n",
    "        source_image_bytes = bytearray(file.read())\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for target_image_path in target_image_paths:\n",
    "        # Convertendo a imagem alvo para o formato binário\n",
    "        with open(target_image_path, 'rb') as file:\n",
    "            target_image_bytes = bytearray(file.read())\n",
    "\n",
    "        # Realizando a comparação\n",
    "        response = client.compare_faces(\n",
    "            SourceImage={'Bytes': source_image_bytes},\n",
    "            TargetImage={'Bytes': target_image_bytes},\n",
    "        )\n",
    "\n",
    "        # Inicializa o estado da autenticação como não autenticado\n",
    "        is_authenticated = False\n",
    "\n",
    "        # Verifica se houve correspondências\n",
    "        if response['FaceMatches']:\n",
    "            # Analisando o resultado de correspondências\n",
    "            for face_match in response['FaceMatches']:\n",
    "                similarity = face_match['Similarity']\n",
    "                if similarity >= similarity_level:\n",
    "                    results[target_image_path] = f\"Imagem autenticada (similaridade: {similarity}%)\"\n",
    "                    is_authenticated = True\n",
    "                    break  # Para de verificar outras correspondências se já autenticado\n",
    "        # Se nenhuma correspondência foi suficiente, ou se não houver correspondência\n",
    "        if not is_authenticated:\n",
    "            results[target_image_path] = f\"Imagem não autenticada (sem correspondências suficientemente similares)\"\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7fLfeNYtfyE"
   },
   "source": [
    "**Filtragem das imagens autenticadas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pjr-kxjV50wo"
   },
   "source": [
    "**Função `ilter_authenticated_images`:**\n",
    "\n",
    "- Filtra apenas as imagens autenticadas: Cria uma lista contendo os caminhos das imagens que têm o status \"Imagem autenticada\" no dicionário `results`.\n",
    "\n",
    "- Retorna imagens autenticadas: Retorna a lista de caminhos das imagens autenticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2SJdcdlFte83"
   },
   "outputs": [],
   "source": [
    "def filter_authenticated_images(results):\n",
    "    # Filtra apenas as imagens autenticadas\n",
    "    authenticated_images = [path for path, verdict in results.items() if \"Imagem autenticada\" in verdict]\n",
    "    return authenticated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbG4GVDh6Hiy"
   },
   "source": [
    "**Nível de similaridade**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux7uVcxR6MSt"
   },
   "source": [
    "Assim como o nível de confiança, também é extremamente importante para a comparação de  imagens.\n",
    "\n",
    "Ele permite controlar a qualidade das correspondências. Se definido um nível muito baixo, pode-se obter correspondências incorretas, com imagens que não são realmente semelhantes. Um nível muito alto pode resultar em menos correspondências, mas com maior precisão.\n",
    "\n",
    "É comum a configuração de níveis de similaridades maiores que 90% para evitar falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "l04fGrqAZe0M"
   },
   "outputs": [],
   "source": [
    "similarity_level = 90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Un4CL3wqW8OR"
   },
   "outputs": [],
   "source": [
    "results = compare_images(file_name_source,\n",
    "               target_image_paths,\n",
    "               similarity_level,\n",
    "               ACCESS_ID,\n",
    "               ACCESS_KEY,\n",
    "               REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbWJ1oAW7LR6"
   },
   "source": [
    "**Veredito para comparação das imagens**\n",
    "\n",
    "É realizada a comparação de cada imagem aprovad (target) com a imagem fonte (CNH) e é apurado se as variáveis targets tem similaridade ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0Tros5DZV-Z",
    "outputId": "e36f7b8f-573f-48b3-8615-ced6d1e00595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagens/chines-1.png: Imagem não autenticada (sem correspondências suficientemente similares)\n",
      "imagens/igor-2.jpg: Imagem autenticada (similaridade: 99.9697494506836%)\n",
      "imagens/igor-5.jpeg: Imagem autenticada (similaridade: 99.27886199951172%)\n",
      "imagens/pedro-1.png: Imagem não autenticada (sem correspondências suficientemente similares)\n",
      "imagens/tulio-1.png: Imagem não autenticada (sem correspondências suficientemente similares)\n"
     ]
    }
   ],
   "source": [
    "for target_image, verdict in results.items():\n",
    "    print(f'{target_image}: {verdict}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIRrXdET7law"
   },
   "source": [
    "Armazenamento das imagens autenticadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UxnLKITPtndO"
   },
   "outputs": [],
   "source": [
    "authenticated_images = filter_authenticated_images(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Yr57UIStpNC",
    "outputId": "ecf9d0d2-5dbf-4733-eb9c-33f43a5de195"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagens/igor-2.jpg', 'imagens/igor-5.jpeg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authenticated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0lrs_Isu4gL"
   },
   "source": [
    "Liveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pw9bV2jI9X67"
   },
   "source": [
    "**Função `detect_liveness`:**\n",
    "\n",
    "- Lê o arquivo da imagem especificado por `image_path` e o converte para o formato binário (`image_bytes`).\n",
    "\n",
    "- Envia a imagem para o serviço Rekognition para análise, solicitando todos os atributos disponíveis, incluindo emoções.\n",
    "\n",
    "- Obtém os detalhes das faces detectadas na resposta.\n",
    "\n",
    "- Analisa as emoções detectadas para inferir a liveness. Se encontrar 5 ou mais emoções com nível de confiança acima do valor especificado (`confidence_level`), retorna `True`, indica que a liveness foi detectada.\n",
    "\n",
    "- Se não encontrar uma emoção indicativa de liveness, retorna `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "XHjBhEBNu5rQ"
   },
   "outputs": [],
   "source": [
    "def detect_liveness(image_path,confidence_level):\n",
    "    # Inicializa a sessão com AWS Rekognition\n",
    "    session = boto3.Session(aws_access_key_id=ACCESS_ID, aws_secret_access_key= ACCESS_KEY)\n",
    "    client = session.client('rekognition', region_name= REGION)\n",
    "\n",
    "    # Lê a imagem\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "\n",
    "    # Realiza a análise de imagem\n",
    "    response = client.detect_faces(\n",
    "        Image={'Bytes': image_bytes},\n",
    "        Attributes=['ALL']  # Inclui todos os atributos, como emoções\n",
    "    )\n",
    "\n",
    "    face_details = response.get('FaceDetails', [])\n",
    "\n",
    "    # Verifica se pelo menos uma face foi detectada\n",
    "    if not face_details:\n",
    "        print(f\"Nenhuma face detectada na imagem {image_path}.\")\n",
    "        return False\n",
    "\n",
    "    # Contador para emoções com alta confiança\n",
    "    emotion_count = 0\n",
    "\n",
    "    # Analisando as emoções para inferir liveness\n",
    "    for face in face_details:\n",
    "        emotions = face.get('Emotions', [])\n",
    "        if emotions:\n",
    "            # Verifica a presença de pelo menos 4 emoções com confiança acima do nível especificado\n",
    "            for emotion in emotions:\n",
    "                if emotion['Confidence'] > confidence_level:\n",
    "                    emotion_count += 1\n",
    "                    if emotion_count >= 5:\n",
    "                        return True\n",
    "\n",
    "    # Caso não tenha encontrado emoções\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmoH9oIevPye"
   },
   "source": [
    "## Autentificação final do usuário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jFiokvA9_aO"
   },
   "source": [
    "**Função `process_authenticated_images`**:\n",
    "\n",
    "\n",
    "- Inicializa dicionário: Cria um dicionário vazio `liveness_results` para armazenar os resultados de detecção de liveness para cada imagem autenticada.\n",
    "\n",
    "- Imagens autenticadas:\n",
    "  - Para cada caminho de imagem na lista `authenticated_images`:\n",
    "    - Chama a função `detect_liveness` para verificar a presença de liveness na imagem, usando o nível de confiança especificado (`confidence_level`).\n",
    "    - Armazena o resultado (`True` ou `False`) no dicionário `liveness_results`, associando-o ao caminho da imagem.\n",
    "\n",
    "- Verificação de Liveness:\n",
    "  - Usa a função `all` para verificar se todas as imagens autenticadas têm liveness detectada (ou seja, se todos os valores no dicionário `liveness_results` são `True`).\n",
    "\n",
    "- Imprime mensagem final de autenticação final do usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vI2PXnHrvPfp"
   },
   "outputs": [],
   "source": [
    "def process_authenticated_images(authenticated_images,confidence_level):\n",
    "    liveness_results = {}\n",
    "    for image_path in authenticated_images:\n",
    "        liveness_detected = detect_liveness(image_path,confidence_level)\n",
    "        liveness_results[image_path] = liveness_detected\n",
    "\n",
    "    # Determina se todas as imagens têm liveness detectada\n",
    "    all_authenticated = all(liveness_results.values())\n",
    "\n",
    "    if all_authenticated:\n",
    "        print(\"O usuário foi aprovado para entrar na plataforma.\")\n",
    "    else:\n",
    "        print(\"O usuário foi encaminhado para o atendimento. Liveness não detectada em pelo menos uma imagem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLbJs3gMvTu9",
    "outputId": "5fc94bb9-8c78-4c5b-d0a2-d138b3e9ed1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O usuário foi encaminhado para o atendimento. Liveness não detectada em pelo menos uma imagem.\n"
     ]
    }
   ],
   "source": [
    "process_authenticated_images(authenticated_images,confidence_level)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
